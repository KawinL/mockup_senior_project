{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim, os, re\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load & train word2vec model\n",
    "model = gensim.models.Word2Vec.load('/Users/AUM/Documents/PROJECT/mockup_senior_project/thai_text_mock_up/word2vec/w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in model.wv.vocab:\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 30225\n"
     ]
    }
   ],
   "source": [
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: สุขุมวิท, Similarity: 0.71\n",
      "Word: เอกมัย, Similarity: 0.68\n",
      "Word: สีลม, Similarity: 0.67\n",
      "Word: รัชดาภิเษก, Similarity: 0.67\n",
      "Word: พญาไท, Similarity: 0.63\n",
      "Word: เพชรเกษม, Similarity: 0.61\n",
      "Word: อังรีดูนังต์, Similarity: 0.59\n",
      "Word: สุวินทวงศ์, Similarity: 0.59\n",
      "Word: จตุจักร, Similarity: 0.58\n",
      "Word: พลาซ่า, Similarity: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Pick a word \n",
    "find_similar_to = 'ลาดพร้าว'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : ครับ , Similarity: 0.59\n",
      "Word : ครับ? , Similarity: 0.52\n",
      "Word : คับ , Similarity: 0.49\n",
      "Word : ครับ... , Similarity: 0.48\n",
      "Word : คะ? , Similarity: 0.48\n",
      "Word : เหรอ , Similarity: 0.46\n",
      "Word : ดิฉัน , Similarity: 0.46\n",
      "Word : อ่ะ , Similarity: 0.45\n",
      "Word : ปล. , Similarity: 0.42\n",
      "Word : อะไร , Similarity: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Test words \n",
    "word_add = ['นางสาว', 'ค่ะ']\n",
    "word_sub = ['นาย']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    "):\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Limit number of tokens to be visualized\n",
    "limit = 500\n",
    "vector_dim = 100\n",
    "# Getting tokens and vectors\n",
    "words = []\n",
    "embedding = np.array([])\n",
    "i = 0\n",
    "for word in model.wv.vocab:\n",
    "    # Break the loop if limit exceeds \n",
    "    if i == limit: break\n",
    "\n",
    "    # Getting token \n",
    "    words.append(word)\n",
    "\n",
    "    # Appending the vectors \n",
    "    embedding = np.append(embedding, model[word])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Reshaping the embedding vector \n",
    "embedding = embedding.reshape(limit, vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ThaiFont = FontProperties(fname = '/Users/AUM/Library/Fonts/THSarabunChula-Regular.ttf')\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom',\n",
    "                 fontproperties = ThaiFont)\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    \n",
    "# Creating the tsne plot [Warning: will take time]\n",
    "tsne = TSNE(perplexity=30.0, n_components=2, init='pca', n_iter=5000)\n",
    "\n",
    "low_dim_embedding = tsne.fit_transform(embedding)\n",
    "\n",
    "# Finally plotting and saving the fig \n",
    "plot_with_labels(low_dim_embedding, words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
